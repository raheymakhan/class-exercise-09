{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The ninth in-class-exercise (20 points in total, 11/11/2020)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
    "\n",
    "The dataset can be download from here: https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
    "\n",
    "Algorithms:\n",
    "\n",
    "(1) MultinominalNB\n",
    "\n",
    "(2) SVM \n",
    "\n",
    "(3) KNN \n",
    "\n",
    "(4) Decision tree\n",
    "\n",
    "(5) Random Forest\n",
    "\n",
    "(6) XGBoost\n",
    "\n",
    "Evaluation measurement:\n",
    "\n",
    "(1) Accuracy\n",
    "\n",
    "(2) Recall\n",
    "\n",
    "(3) Precison \n",
    "\n",
    "(4) F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING THE TRAIN, VALIDATE AND TEST DATASETS\n",
    "\n",
    "# Opening the stsa-train text file as a pandas dataframe.\n",
    "import pandas as pd\n",
    "stsa_train = pd.read_fwf(r\"C:/Users/Raheyma Arshad/Desktop/stsa-train.txt\", header = None)\n",
    "del stsa_train[2]\n",
    "stsa_train = stsa_train.rename(columns={0: \"Sentiment\", 1: \"Text\"})\n",
    "\n",
    "# Splitting the stsa_train dataframe into training and validation datasets.\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_validate, y_train, y_validate = sklearn.model_selection.train_test_split(stsa_train['Text'], stsa_train['Sentiment'], train_size=0.8, test_size=0.2)\n",
    "\n",
    "# Converting the training data x(text) and y(sentiments) values into numpy arrays.\n",
    "import numpy\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "# Opening the stsa-test text file as a pandas dataframe for Evaluation Measurement\n",
    "test = pd.read_fwf(r\"C:/Users/Raheyma Arshad/Desktop/stsa-test.txt\", header = None)\n",
    "del test[2]\n",
    "del test[3]\n",
    "test = test.rename(columns={0: \"Sentiment\", 1: \"Text\"})\n",
    "\n",
    "# Setting the number of K-folds to 10.\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions for validation dataset are:\n",
      "       Actual  Predicted\n",
      "4579       0          1\n",
      "1041       0          0\n",
      "3139       1          0\n",
      "5654       1          1\n",
      "4173       1          1\n",
      "\n",
      "The accuracy of MultinomialNB is: 80.34047226798462\n",
      "The recall of MultinomialNB is: 0.88998899889989\n",
      "The precision of MultinomialNB is: 0.8034047226798462\n",
      "The f1-score of MultinomialNB is: 0.8019699782747107\n"
     ]
    }
   ],
   "source": [
    "# ALGORITHM: (1) MultinominalNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
    "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
    "    \n",
    "    algorithm = pipeline.fit(x_train_k, y_train_k)\n",
    "\n",
    "pred_validate = algorithm.predict(x_validate)\n",
    "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
    "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])\n",
    "print('The predictions for validation dataset are:\\n', validation_df.head())\n",
    "\n",
    "# EVALUATION MEASUREMENT:\n",
    "\n",
    "pred_test = algorithm.predict(test['Text'])\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# (1) Accuracy\n",
    "print('\\nThe accuracy of MultinomialNB is:', (accuracy_score(test['Sentiment'], pred_test)*100))\n",
    "# (2) Recall\n",
    "print('The recall of MultinomialNB is:', recall_score(test['Sentiment'], pred_test))\n",
    "# (3) Precison \n",
    "print('The precision of MultinomialNB is:', accuracy_score(test['Sentiment'], pred_test))\n",
    "# (4) F-1 score\n",
    "print('The f1-score of MultinomialNB is:', f1_score(test['Sentiment'], pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions for validation dataset are:\n",
      "       Actual  Predicted\n",
      "4579       0          1\n",
      "1041       0          0\n",
      "3139       1          0\n",
      "5654       1          1\n",
      "4173       1          1\n",
      "\n",
      "The accuracy of SVM is: 79.07742998352553\n",
      "The recall of SVM is: 0.801980198019802\n",
      "The precision of SVM is: 0.7907742998352554\n",
      "The f1-score of SVM is: 0.790753855048546\n"
     ]
    }
   ],
   "source": [
    "# ALGORITHM: (2) SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC())])\n",
    "\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
    "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
    "    \n",
    "    algorithm = pipeline.fit(x_train_k, y_train_k)\n",
    "\n",
    "pred_validate = algorithm.predict(x_validate)\n",
    "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
    "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])\n",
    "print('The predictions for validation dataset are:\\n', validation_df.head())\n",
    "\n",
    "# EVALUATION MEASUREMENT:\n",
    "\n",
    "pred_test = algorithm.predict(test['Text'])\n",
    "\n",
    "# (1) Accuracy\n",
    "print('\\nThe accuracy of SVM is:', (accuracy_score(test['Sentiment'], pred_test)*100))\n",
    "# (2) Recall\n",
    "print('The recall of SVM is:', recall_score(test['Sentiment'], pred_test))\n",
    "# (3) Precison \n",
    "print('The precision of SVM is:', accuracy_score(test['Sentiment'], pred_test))\n",
    "# (4) F-1 score\n",
    "print('The f1-score of SVM is:', f1_score(test['Sentiment'], pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions for validation dataset are:\n",
      "       Actual  Predicted\n",
      "4579       0          1\n",
      "1041       0          0\n",
      "3139       1          0\n",
      "5654       1          0\n",
      "4173       1          1\n",
      "\n",
      "The accuracy of KNN is: 72.15815485996706\n",
      "The recall of KNN is: 0.7601760176017601\n",
      "The precision of KNN is: 0.7215815485996705\n",
      "The f1-score of KNN is: 0.7211927703457464\n"
     ]
    }
   ],
   "source": [
    "# ALGORITHM: (3) KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier())])\n",
    "\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
    "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
    "    \n",
    "    algorithm = pipeline.fit(x_train_k, y_train_k)\n",
    "\n",
    "pred_validate = algorithm.predict(x_validate)\n",
    "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
    "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])\n",
    "print('The predictions for validation dataset are:\\n', validation_df.head())\n",
    "\n",
    "# EVALUATION MEASUREMENT:\n",
    "\n",
    "pred_test = algorithm.predict(test['Text'])\n",
    "\n",
    "# (1) Accuracy\n",
    "print('\\nThe accuracy of KNN is:', (accuracy_score(test['Sentiment'], pred_test)*100))\n",
    "# (2) Recall\n",
    "print('The recall of KNN is:', recall_score(test['Sentiment'], pred_test))\n",
    "# (3) Precison \n",
    "print('The precision of KNN is:', accuracy_score(test['Sentiment'], pred_test))\n",
    "# (4) F-1 score\n",
    "print('The f1-score of KNN is:', f1_score(test['Sentiment'], pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions for validation dataset are:\n",
      "       Actual  Predicted\n",
      "4579       0          1\n",
      "1041       0          0\n",
      "3139       1          0\n",
      "5654       1          0\n",
      "4173       1          1\n",
      "\n",
      "The accuracy of Decision Tree is: 60.57111477210324\n",
      "The recall of Decision Tree is: 0.6545654565456546\n",
      "The precision of Decision Tree is: 0.6057111477210324\n",
      "The f1-score of Decision Tree is: 0.604809108252994\n"
     ]
    }
   ],
   "source": [
    "# ALGORITHM: (4) Decision Tree\n",
    "\n",
    "from sklearn import tree\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', tree.DecisionTreeClassifier())])\n",
    "\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
    "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
    "    \n",
    "    algorithm = pipeline.fit(x_train_k, y_train_k)\n",
    "\n",
    "pred_validate = algorithm.predict(x_validate)\n",
    "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
    "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])\n",
    "print('The predictions for validation dataset are:\\n', validation_df.head())\n",
    "\n",
    "# EVALUATION MEASUREMENT:\n",
    "\n",
    "pred_test = algorithm.predict(test['Text'])\n",
    "\n",
    "# (1) Accuracy\n",
    "print('\\nThe accuracy of Decision Tree is:', (accuracy_score(test['Sentiment'], pred_test)*100))\n",
    "# (2) Recall\n",
    "print('The recall of Decision Tree is:', recall_score(test['Sentiment'], pred_test))\n",
    "# (3) Precison \n",
    "print('The precision of Decision Tree is:', accuracy_score(test['Sentiment'], pred_test))\n",
    "# (4) F-1 score\n",
    "print('The f1-score of Decision Tree is:', f1_score(test['Sentiment'], pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions for validation dataset are:\n",
      "       Actual  Predicted\n",
      "4579       0          1\n",
      "1041       0          0\n",
      "3139       1          0\n",
      "5654       1          0\n",
      "4173       1          0\n",
      "\n",
      "The accuracy of Random Forest is: 72.04832509610104\n",
      "The recall of Random Forest is: 0.7832783278327833\n",
      "The precision of Random Forest is: 0.7204832509610104\n",
      "The f1-score of Random Forest is: 0.7194218732452308\n"
     ]
    }
   ],
   "source": [
    "# ALGORITHM: (5) Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
    "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
    "    \n",
    "    algorithm = pipeline.fit(x_train_k, y_train_k)\n",
    "\n",
    "pred_validate = algorithm.predict(x_validate)\n",
    "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
    "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])\n",
    "print('The predictions for validation dataset are:\\n', validation_df.head())\n",
    "\n",
    "# EVALUATION MEASUREMENT:\n",
    "\n",
    "pred_test = algorithm.predict(test['Text'])\n",
    "\n",
    "# (1) Accuracy\n",
    "print('\\nThe accuracy of Random Forest is:', (accuracy_score(test['Sentiment'], pred_test)*100))\n",
    "# (2) Recall\n",
    "print('The recall of Random Forest is:', recall_score(test['Sentiment'], pred_test))\n",
    "# (3) Precison \n",
    "print('The precision of Random Forest is:', accuracy_score(test['Sentiment'], pred_test))\n",
    "# (4) F-1 score\n",
    "print('The f1-score of Random Forest is:', f1_score(test['Sentiment'], pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3754            8.07s\n",
      "         2           1.3680            6.29s\n",
      "         3           1.3615            5.35s\n",
      "         4           1.3558            4.66s\n",
      "         5           1.3507            4.12s\n",
      "         6           1.3461            3.90s\n",
      "         7           1.3409            3.63s\n",
      "         8           1.3369            3.49s\n",
      "         9           1.3330            3.32s\n",
      "        10           1.3287            3.23s\n",
      "        11           1.3256            3.08s\n",
      "        12           1.3219            2.99s\n",
      "        13           1.3190            2.94s\n",
      "        14           1.3160            2.79s\n",
      "        15           1.3123            2.70s\n",
      "        16           1.3092            2.65s\n",
      "        17           1.3060            2.55s\n",
      "        18           1.3030            2.44s\n",
      "        19           1.3005            2.37s\n",
      "        20           1.2976            2.26s\n",
      "        21           1.2948            2.17s\n",
      "        22           1.2923            2.07s\n",
      "        23           1.2897            1.98s\n",
      "        24           1.2868            1.88s\n",
      "        25           1.2845            1.79s\n",
      "        26           1.2820            1.71s\n",
      "        27           1.2794            1.64s\n",
      "        28           1.2771            1.56s\n",
      "        29           1.2749            1.50s\n",
      "        30           1.2729            1.42s\n",
      "        31           1.2704            1.34s\n",
      "        32           1.2686            1.28s\n",
      "        33           1.2664            1.20s\n",
      "        34           1.2638            1.12s\n",
      "        35           1.2615            1.04s\n",
      "        36           1.2597            0.97s\n",
      "        37           1.2573            0.90s\n",
      "        38           1.2554            0.82s\n",
      "        39           1.2532            0.75s\n",
      "        40           1.2510            0.69s\n",
      "        41           1.2492            0.62s\n",
      "        42           1.2469            0.54s\n",
      "        43           1.2449            0.47s\n",
      "        44           1.2433            0.40s\n",
      "        45           1.2415            0.34s\n",
      "        46           1.2398            0.27s\n",
      "        47           1.2372            0.20s\n",
      "        48           1.2351            0.13s\n",
      "        49           1.2335            0.07s\n",
      "        50           1.2319            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3749            2.80s\n",
      "         2           1.3671            2.59s\n",
      "         3           1.3605            2.62s\n",
      "         4           1.3549            2.84s\n",
      "         5           1.3501            2.78s\n",
      "         6           1.3454            2.63s\n",
      "         7           1.3415            2.58s\n",
      "         8           1.3371            2.54s\n",
      "         9           1.3328            2.50s\n",
      "        10           1.3293            2.43s\n",
      "        11           1.3255            2.38s\n",
      "        12           1.3222            2.38s\n",
      "        13           1.3192            2.32s\n",
      "        14           1.3161            2.29s\n",
      "        15           1.3131            2.23s\n",
      "        16           1.3095            2.18s\n",
      "        17           1.3064            2.13s\n",
      "        18           1.3036            2.06s\n",
      "        19           1.3012            2.09s\n",
      "        20           1.2984            2.21s\n",
      "        21           1.2955            2.18s\n",
      "        22           1.2926            2.13s\n",
      "        23           1.2902            2.05s\n",
      "        24           1.2877            1.97s\n",
      "        25           1.2852            1.89s\n",
      "        26           1.2824            1.85s\n",
      "        27           1.2799            1.77s\n",
      "        28           1.2767            1.69s\n",
      "        29           1.2748            1.61s\n",
      "        30           1.2724            1.53s\n",
      "        31           1.2702            1.45s\n",
      "        32           1.2679            1.37s\n",
      "        33           1.2657            1.29s\n",
      "        34           1.2637            1.22s\n",
      "        35           1.2615            1.15s\n",
      "        36           1.2594            1.07s\n",
      "        37           1.2577            0.99s\n",
      "        38           1.2553            0.92s\n",
      "        39           1.2534            0.85s\n",
      "        40           1.2518            0.79s\n",
      "        41           1.2502            0.72s\n",
      "        42           1.2477            0.64s\n",
      "        43           1.2460            0.55s\n",
      "        44           1.2437            0.47s\n",
      "        45           1.2416            0.39s\n",
      "        46           1.2395            0.31s\n",
      "        47           1.2375            0.23s\n",
      "        48           1.2359            0.15s\n",
      "        49           1.2341            0.08s\n",
      "        50           1.2323            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3758            2.67s\n",
      "         2           1.3684            2.67s\n",
      "         3           1.3622            2.68s\n",
      "         4           1.3565            2.61s\n",
      "         5           1.3517            2.67s\n",
      "         6           1.3472            2.60s\n",
      "         7           1.3428            2.54s\n",
      "         8           1.3389            2.69s\n",
      "         9           1.3348            2.60s\n",
      "        10           1.3309            2.52s\n",
      "        11           1.3272            2.47s\n",
      "        12           1.3239            2.37s\n",
      "        13           1.3206            2.31s\n",
      "        14           1.3177            2.22s\n",
      "        15           1.3143            2.19s\n",
      "        16           1.3114            2.12s\n",
      "        17           1.3082            2.04s\n",
      "        18           1.3054            1.98s\n",
      "        19           1.3029            1.91s\n",
      "        20           1.2996            1.84s\n",
      "        21           1.2966            1.78s\n",
      "        22           1.2943            1.72s\n",
      "        23           1.2916            1.70s\n",
      "        24           1.2888            1.67s\n",
      "        25           1.2864            1.62s\n",
      "        26           1.2841            1.56s\n",
      "        27           1.2818            1.49s\n",
      "        28           1.2796            1.43s\n",
      "        29           1.2765            1.36s\n",
      "        30           1.2739            1.29s\n",
      "        31           1.2721            1.22s\n",
      "        32           1.2699            1.15s\n",
      "        33           1.2674            1.10s\n",
      "        34           1.2649            1.03s\n",
      "        35           1.2628            0.96s\n",
      "        36           1.2605            0.90s\n",
      "        37           1.2583            0.83s\n",
      "        38           1.2560            0.76s\n",
      "        39           1.2540            0.70s\n",
      "        40           1.2514            0.64s\n",
      "        41           1.2497            0.57s\n",
      "        42           1.2481            0.51s\n",
      "        43           1.2456            0.44s\n",
      "        44           1.2435            0.38s\n",
      "        45           1.2415            0.32s\n",
      "        46           1.2396            0.26s\n",
      "        47           1.2378            0.19s\n",
      "        48           1.2357            0.13s\n",
      "        49           1.2338            0.06s\n",
      "        50           1.2324            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3763            2.77s\n",
      "         2           1.3691            2.78s\n",
      "         3           1.3630            2.73s\n",
      "         4           1.3575            2.98s\n",
      "         5           1.3524            2.89s\n",
      "         6           1.3477            2.80s\n",
      "         7           1.3431            2.70s\n",
      "         8           1.3389            2.73s\n",
      "         9           1.3348            2.64s\n",
      "        10           1.3312            2.57s\n",
      "        11           1.3273            2.47s\n",
      "        12           1.3238            2.36s\n",
      "        13           1.3204            2.33s\n",
      "        14           1.3180            2.24s\n",
      "        15           1.3145            2.15s\n",
      "        16           1.3113            2.08s\n",
      "        17           1.3083            2.05s\n",
      "        18           1.3053            1.98s\n",
      "        19           1.3029            1.90s\n",
      "        20           1.2999            1.84s\n",
      "        21           1.2971            1.79s\n",
      "        22           1.2944            1.72s\n",
      "        23           1.2920            1.65s\n",
      "        24           1.2895            1.59s\n",
      "        25           1.2866            1.53s\n",
      "        26           1.2840            1.47s\n",
      "        27           1.2812            1.42s\n",
      "        28           1.2790            1.38s\n",
      "        29           1.2759            1.32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        30           1.2736            1.26s\n",
      "        31           1.2705            1.20s\n",
      "        32           1.2688            1.13s\n",
      "        33           1.2664            1.06s\n",
      "        34           1.2639            1.00s\n",
      "        35           1.2617            0.93s\n",
      "        36           1.2599            0.87s\n",
      "        37           1.2576            0.81s\n",
      "        38           1.2554            0.75s\n",
      "        39           1.2531            0.68s\n",
      "        40           1.2513            0.62s\n",
      "        41           1.2494            0.56s\n",
      "        42           1.2468            0.50s\n",
      "        43           1.2446            0.43s\n",
      "        44           1.2425            0.37s\n",
      "        45           1.2405            0.31s\n",
      "        46           1.2383            0.25s\n",
      "        47           1.2356            0.19s\n",
      "        48           1.2335            0.13s\n",
      "        49           1.2316            0.06s\n",
      "        50           1.2294            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3754            3.15s\n",
      "         2           1.3674            2.94s\n",
      "         3           1.3607            2.84s\n",
      "         4           1.3548            2.85s\n",
      "         5           1.3494            2.68s\n",
      "         6           1.3444            2.67s\n",
      "         7           1.3402            2.61s\n",
      "         8           1.3362            2.50s\n",
      "         9           1.3322            2.43s\n",
      "        10           1.3289            2.34s\n",
      "        11           1.3260            2.27s\n",
      "        12           1.3227            2.20s\n",
      "        13           1.3195            2.13s\n",
      "        14           1.3161            2.08s\n",
      "        15           1.3124            2.04s\n",
      "        16           1.3088            1.97s\n",
      "        17           1.3053            1.92s\n",
      "        18           1.3020            1.86s\n",
      "        19           1.2998            1.79s\n",
      "        20           1.2969            1.73s\n",
      "        21           1.2940            1.66s\n",
      "        22           1.2915            1.62s\n",
      "        23           1.2884            1.55s\n",
      "        24           1.2859            1.51s\n",
      "        25           1.2835            1.45s\n",
      "        26           1.2803            1.42s\n",
      "        27           1.2775            1.37s\n",
      "        28           1.2749            1.30s\n",
      "        29           1.2726            1.24s\n",
      "        30           1.2696            1.19s\n",
      "        31           1.2677            1.13s\n",
      "        32           1.2654            1.07s\n",
      "        33           1.2631            1.01s\n",
      "        34           1.2608            0.95s\n",
      "        35           1.2589            0.89s\n",
      "        36           1.2563            0.83s\n",
      "        37           1.2544            0.77s\n",
      "        38           1.2523            0.71s\n",
      "        39           1.2499            0.65s\n",
      "        40           1.2480            0.60s\n",
      "        41           1.2462            0.54s\n",
      "        42           1.2442            0.48s\n",
      "        43           1.2421            0.42s\n",
      "        44           1.2404            0.36s\n",
      "        45           1.2378            0.30s\n",
      "        46           1.2353            0.24s\n",
      "        47           1.2336            0.18s\n",
      "        48           1.2317            0.12s\n",
      "        49           1.2296            0.06s\n",
      "        50           1.2279            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3755            3.91s\n",
      "         2           1.3682            4.09s\n",
      "         3           1.3616            3.90s\n",
      "         4           1.3559            3.75s\n",
      "         5           1.3508            3.60s\n",
      "         6           1.3462            3.50s\n",
      "         7           1.3417            3.35s\n",
      "         8           1.3377            3.24s\n",
      "         9           1.3339            3.20s\n",
      "        10           1.3299            3.08s\n",
      "        11           1.3263            3.09s\n",
      "        12           1.3233            3.03s\n",
      "        13           1.3198            2.88s\n",
      "        14           1.3167            2.74s\n",
      "        15           1.3131            2.59s\n",
      "        16           1.3099            2.50s\n",
      "        17           1.3073            2.42s\n",
      "        18           1.3038            2.32s\n",
      "        19           1.3008            2.22s\n",
      "        20           1.2977            2.14s\n",
      "        21           1.2950            2.05s\n",
      "        22           1.2918            1.98s\n",
      "        23           1.2893            1.90s\n",
      "        24           1.2866            1.81s\n",
      "        25           1.2841            1.74s\n",
      "        26           1.2815            1.67s\n",
      "        27           1.2794            1.59s\n",
      "        28           1.2764            1.51s\n",
      "        29           1.2741            1.45s\n",
      "        30           1.2720            1.36s\n",
      "        31           1.2694            1.29s\n",
      "        32           1.2671            1.21s\n",
      "        33           1.2651            1.14s\n",
      "        34           1.2621            1.07s\n",
      "        35           1.2599            1.00s\n",
      "        36           1.2580            0.93s\n",
      "        37           1.2557            0.88s\n",
      "        38           1.2536            0.81s\n",
      "        39           1.2515            0.74s\n",
      "        40           1.2498            0.68s\n",
      "        41           1.2476            0.63s\n",
      "        42           1.2452            0.58s\n",
      "        43           1.2430            0.50s\n",
      "        44           1.2412            0.43s\n",
      "        45           1.2390            0.36s\n",
      "        46           1.2369            0.29s\n",
      "        47           1.2345            0.22s\n",
      "        48           1.2327            0.14s\n",
      "        49           1.2305            0.07s\n",
      "        50           1.2286            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3758            4.16s\n",
      "         2           1.3682            3.64s\n",
      "         3           1.3619            3.62s\n",
      "         4           1.3561            3.56s\n",
      "         5           1.3509            3.38s\n",
      "         6           1.3461            3.34s\n",
      "         7           1.3417            3.21s\n",
      "         8           1.3377            3.04s\n",
      "         9           1.3336            2.89s\n",
      "        10           1.3301            2.83s\n",
      "        11           1.3271            2.72s\n",
      "        12           1.3240            2.62s\n",
      "        13           1.3208            2.57s\n",
      "        14           1.3175            2.49s\n",
      "        15           1.3138            2.38s\n",
      "        16           1.3112            2.29s\n",
      "        17           1.3075            2.20s\n",
      "        18           1.3044            2.14s\n",
      "        19           1.3019            2.06s\n",
      "        20           1.2992            1.98s\n",
      "        21           1.2969            1.90s\n",
      "        22           1.2940            1.82s\n",
      "        23           1.2906            1.75s\n",
      "        24           1.2873            1.68s\n",
      "        25           1.2845            1.62s\n",
      "        26           1.2819            1.55s\n",
      "        27           1.2793            1.48s\n",
      "        28           1.2767            1.42s\n",
      "        29           1.2738            1.35s\n",
      "        30           1.2718            1.28s\n",
      "        31           1.2695            1.22s\n",
      "        32           1.2678            1.15s\n",
      "        33           1.2658            1.08s\n",
      "        34           1.2627            1.01s\n",
      "        35           1.2608            0.95s\n",
      "        36           1.2585            0.89s\n",
      "        37           1.2566            0.82s\n",
      "        38           1.2543            0.75s\n",
      "        39           1.2521            0.69s\n",
      "        40           1.2496            0.63s\n",
      "        41           1.2471            0.57s\n",
      "        42           1.2446            0.51s\n",
      "        43           1.2428            0.44s\n",
      "        44           1.2407            0.38s\n",
      "        45           1.2387            0.31s\n",
      "        46           1.2368            0.25s\n",
      "        47           1.2346            0.19s\n",
      "        48           1.2326            0.12s\n",
      "        49           1.2308            0.06s\n",
      "        50           1.2291            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3763            2.81s\n",
      "         2           1.3691            2.91s\n",
      "         3           1.3627            2.72s\n",
      "         4           1.3569            2.64s\n",
      "         5           1.3517            2.61s\n",
      "         6           1.3471            2.50s\n",
      "         7           1.3426            2.49s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         8           1.3383            2.47s\n",
      "         9           1.3344            2.38s\n",
      "        10           1.3307            2.34s\n",
      "        11           1.3267            2.26s\n",
      "        12           1.3230            2.19s\n",
      "        13           1.3201            2.10s\n",
      "        14           1.3171            2.03s\n",
      "        15           1.3139            1.97s\n",
      "        16           1.3107            1.90s\n",
      "        17           1.3076            1.86s\n",
      "        18           1.3048            1.82s\n",
      "        19           1.3019            1.75s\n",
      "        20           1.2994            1.69s\n",
      "        21           1.2967            1.63s\n",
      "        22           1.2933            1.58s\n",
      "        23           1.2905            1.51s\n",
      "        24           1.2874            1.45s\n",
      "        25           1.2846            1.41s\n",
      "        26           1.2824            1.35s\n",
      "        27           1.2800            1.30s\n",
      "        28           1.2776            1.25s\n",
      "        29           1.2745            1.19s\n",
      "        30           1.2726            1.14s\n",
      "        31           1.2705            1.09s\n",
      "        32           1.2681            1.03s\n",
      "        33           1.2655            0.97s\n",
      "        34           1.2631            0.91s\n",
      "        35           1.2612            0.86s\n",
      "        36           1.2589            0.80s\n",
      "        37           1.2566            0.74s\n",
      "        38           1.2546            0.69s\n",
      "        39           1.2513            0.63s\n",
      "        40           1.2495            0.58s\n",
      "        41           1.2475            0.52s\n",
      "        42           1.2455            0.46s\n",
      "        43           1.2434            0.40s\n",
      "        44           1.2409            0.35s\n",
      "        45           1.2391            0.29s\n",
      "        46           1.2373            0.23s\n",
      "        47           1.2355            0.17s\n",
      "        48           1.2337            0.12s\n",
      "        49           1.2316            0.06s\n",
      "        50           1.2297            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3757            2.93s\n",
      "         2           1.3681            2.84s\n",
      "         3           1.3616            2.74s\n",
      "         4           1.3559            2.70s\n",
      "         5           1.3506            2.64s\n",
      "         6           1.3458            2.61s\n",
      "         7           1.3412            2.50s\n",
      "         8           1.3371            2.45s\n",
      "         9           1.3328            2.39s\n",
      "        10           1.3292            2.31s\n",
      "        11           1.3261            2.23s\n",
      "        12           1.3228            2.17s\n",
      "        13           1.3192            2.13s\n",
      "        14           1.3158            2.05s\n",
      "        15           1.3127            2.00s\n",
      "        16           1.3101            1.93s\n",
      "        17           1.3070            1.88s\n",
      "        18           1.3045            1.81s\n",
      "        19           1.3019            1.74s\n",
      "        20           1.2993            1.68s\n",
      "        21           1.2968            1.63s\n",
      "        22           1.2941            1.58s\n",
      "        23           1.2915            1.52s\n",
      "        24           1.2890            1.46s\n",
      "        25           1.2862            1.41s\n",
      "        26           1.2840            1.35s\n",
      "        27           1.2810            1.29s\n",
      "        28           1.2786            1.23s\n",
      "        29           1.2762            1.18s\n",
      "        30           1.2738            1.12s\n",
      "        31           1.2720            1.06s\n",
      "        32           1.2701            1.01s\n",
      "        33           1.2681            0.96s\n",
      "        34           1.2660            0.90s\n",
      "        35           1.2636            0.85s\n",
      "        36           1.2614            0.79s\n",
      "        37           1.2594            0.74s\n",
      "        38           1.2569            0.69s\n",
      "        39           1.2545            0.64s\n",
      "        40           1.2524            0.58s\n",
      "        41           1.2504            0.52s\n",
      "        42           1.2485            0.46s\n",
      "        43           1.2466            0.41s\n",
      "        44           1.2442            0.35s\n",
      "        45           1.2422            0.29s\n",
      "        46           1.2402            0.23s\n",
      "        47           1.2384            0.17s\n",
      "        48           1.2369            0.11s\n",
      "        49           1.2348            0.06s\n",
      "        50           1.2333            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3755            3.25s\n",
      "         2           1.3684            2.98s\n",
      "         3           1.3622            4.08s\n",
      "         4           1.3566            3.94s\n",
      "         5           1.3515            4.64s\n",
      "         6           1.3467            4.58s\n",
      "         7           1.3426            4.14s\n",
      "         8           1.3386            3.82s\n",
      "         9           1.3348            3.68s\n",
      "        10           1.3315            3.46s\n",
      "        11           1.3279            3.26s\n",
      "        12           1.3249            3.13s\n",
      "        13           1.3217            2.97s\n",
      "        14           1.3184            2.84s\n",
      "        15           1.3145            2.71s\n",
      "        16           1.3114            2.61s\n",
      "        17           1.3082            2.50s\n",
      "        18           1.3049            2.38s\n",
      "        19           1.3023            2.28s\n",
      "        20           1.2999            2.19s\n",
      "        21           1.2973            2.09s\n",
      "        22           1.2948            2.00s\n",
      "        23           1.2921            1.93s\n",
      "        24           1.2897            1.84s\n",
      "        25           1.2872            1.75s\n",
      "        26           1.2844            1.67s\n",
      "        27           1.2822            1.58s\n",
      "        28           1.2794            1.49s\n",
      "        29           1.2770            1.42s\n",
      "        30           1.2749            1.34s\n",
      "        31           1.2718            1.27s\n",
      "        32           1.2695            1.20s\n",
      "        33           1.2675            1.12s\n",
      "        34           1.2655            1.05s\n",
      "        35           1.2639            0.98s\n",
      "        36           1.2619            0.91s\n",
      "        37           1.2599            0.84s\n",
      "        38           1.2580            0.77s\n",
      "        39           1.2559            0.70s\n",
      "        40           1.2540            0.64s\n",
      "        41           1.2524            0.57s\n",
      "        42           1.2504            0.51s\n",
      "        43           1.2482            0.44s\n",
      "        44           1.2458            0.38s\n",
      "        45           1.2436            0.31s\n",
      "        46           1.2410            0.25s\n",
      "        47           1.2391            0.19s\n",
      "        48           1.2370            0.12s\n",
      "        49           1.2351            0.06s\n",
      "        50           1.2332            0.00s\n",
      "The predictions for validation dataset are:\n",
      "       Actual  Predicted\n",
      "4579       0          1\n",
      "1041       0          0\n",
      "3139       1          0\n",
      "5654       1          1\n",
      "4173       1          0\n",
      "\n",
      "The accuracy of XGBoost is: 62.54805052169138\n",
      "The recall of XGBoost is: 0.8261826182618262\n",
      "The precision of XGBoost is: 0.6254805052169138\n",
      "The f1-score of XGBoost is: 0.6099824386861423\n"
     ]
    }
   ],
   "source": [
    "# ALGORITHM: (6) XGBoost\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', GradientBoostingClassifier(n_estimators=50,verbose=2))])\n",
    "\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
    "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
    "    \n",
    "    algorithm = pipeline.fit(x_train_k, y_train_k)\n",
    "\n",
    "pred_validate = algorithm.predict(x_validate)\n",
    "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
    "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])\n",
    "print('The predictions for validation dataset are:\\n', validation_df.head())\n",
    "\n",
    "# EVALUATION MEASUREMENT:\n",
    "\n",
    "pred_test = algorithm.predict(test['Text'])\n",
    "\n",
    "# (1) Accuracy\n",
    "print('\\nThe accuracy of XGBoost is:', (accuracy_score(test['Sentiment'], pred_test)*100))\n",
    "# (2) Recall\n",
    "print('The recall of XGBoost is:', recall_score(test['Sentiment'], pred_test))\n",
    "# (3) Precison \n",
    "print('The precision of XGBoost is:', accuracy_score(test['Sentiment'], pred_test))\n",
    "# (4) F-1 score\n",
    "print('The f1-score of XGBoost is:', f1_score(test['Sentiment'], pred_test, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
